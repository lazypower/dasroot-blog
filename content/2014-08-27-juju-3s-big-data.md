Title: Juju <3's Big Data
Date: 2014-08-27 17:08
Tags: juju, planet, big-data, hadoop, hortonworks
Slug: juju-3s-big-data
Category: Devops

<iframe width="640" height="360" src="//www.youtube.com/embed/f9yTWK7Z9Wg" frameborder="0" allowfullscreen></iframe>

> Syndicators, there is a video link above that may not make syndication. Click the source link to view the 10 minute demo video.

Over the past 4 months [Amir Sanjar](http://bigdatachat.net) and I have been working dilligently on Juju's Big Data story. Working with software vendors to charm up big name products like the Demo'd Hortonworks Hadoop distribution.

To those of you that know nothing about Hadoop - Hadoop is a large scale big data framework / suite of applications. It provides facilities to build an entire ecosystem to crunch numbers from seemingly unrelated data sources, and compute through petabytes of data via Map/Reduce applications.

A traditional hadoop deployment consists of a few components:

- Map / Reduce Engine (or cluster of engines)
- Data Warehousing Facility
- Distributed Filesystem to cache results across the cluster
- Data sources (MySQL, MongoDB, HBASE, Couch, PostGRES just to name a few)

Setting up these different services and interconnecting them can be a full day process for a seasoned professional in the Big Data ecosystem. Juju offers you a quick way to distill all of that setup and interconnectivity knowledge so you can be a master at USING hadoop. Not at deploying it.

Some people say Juju negates the need to read the book, and while this may be true; I still advise you read the book at least once - so you know how it's put together, why certain configurations were chosen, and how to troubleshoot the bundle should anything go wrong. Then you're free to wield the community provided Hadoop bundle(s) like a pro.

Enjoy the Demo, and look for more Big Data tools and products on the [Juju Charm Store](http://jujucharms.com)
